# -*- coding: utf-8 -*-
"""EmployeeSalaryprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d0mrF4ZD2uSUufWbFpkZgCKqRDg2Pr1A
"""

#Employee Salary Prediction using adult csv
#Load your library
import pandas as pd

data = pd.read_csv("/adult.csv")

data

data.shape

# Finding null values
data.isna().sum()

print(data.workclass.value_counts())

data.workclass.replace({'?':'Others'},inplace=True)
print(data['workclass'].value_counts())

print(data.occupation.value_counts())

data.occupation.replace({'?':'Others'},inplace=True)
print(data['occupation'].value_counts())

print(data.gender.value_counts())

print(data['education'].value_counts())

print(data['marital-status'].value_counts())

data

print(data.fnlwgt.value_counts())

print(data.relationship.value_counts())

print(data.race.value_counts())

print(data['capital-gain'].value_counts())

print(data['native-country'].value_counts())

data['native-country'].replace({'?':'Others'},inplace=True)
print(data['native-country'].value_counts())

# Removing less important data
print(data['workclass'].value_counts())

data=data[data['workclass']!='Without-pay']
data=data[data['workclass']!='Never-worked']
print(data['workclass'].value_counts())

print(data['education'].value_counts())

data=data[data['education']!='Preschool']
print(data['education'].value_counts())

print(data['marital-status'].value_counts())

data=data[data['marital-status']!='Married-AF-spouse']
print(data['marital-status'].value_counts())

print(data['occupation'].value_counts())

data=data[data['occupation']!='Armed-Forces']
data=data[data['occupation']!='Priv-house-serv']
print(data['occupation'].value_counts())

print(data['relationship'].value_counts())

print(data['race'].value_counts())

print(data['gender'].value_counts())

print(data['native-country'].value_counts())

data=data[data['native-country']!='Holand-Netherlands']

#redundancy so we delete education col
data.drop(columns=['education'],inplace=True)

data

data.shape

#outlier detection
import matplotlib.pyplot as plt
plt.boxplot(data['age'])
plt.show()
plt.boxplot(data['educational-num'])
plt.show()
plt.boxplot(data['capital-gain'])
plt.show()
plt.boxplot(data['capital-loss'])
plt.show()
plt.boxplot(data['hours-per-week'])
plt.show()

data=data[(data['age']<=75) & (data['age']>=17)]

data=data[(data['educational-num']<=16)&(data['educational-num']>=5)]

# Remove capital-gain outliers (most are 0; remove very high spikes)
data = data[(data['capital-gain'] <= 20000)]

# Remove capital-loss outliers
data = data[(data['capital-loss'] <= 2500)]

# Remove hours-per-week outliers (practical working range)
data = data[(data['hours-per-week'] >= 20) & (data['hours-per-week'] <= 60)]

plt.boxplot(data['age'])
plt.show()
plt.boxplot(data['educational-num'])
plt.show()
plt.boxplot(data['capital-gain'])
plt.show()
plt.boxplot(data['capital-loss'])
plt.show()
plt.boxplot(data['hours-per-week'])
plt.show()

data.shape

data

# Label encoding
from sklearn.preprocessing import LabelEncoder
import joblib

# Create and save separate encoders
workclass_encoder = LabelEncoder()
data['workclass'] = workclass_encoder.fit_transform(data['workclass'])
joblib.dump(workclass_encoder, "workclass_encoder.pkl")

occupation_encoder = LabelEncoder()
data['occupation'] = occupation_encoder.fit_transform(data['occupation'])
joblib.dump(occupation_encoder, "occupation_encoder.pkl")

relationship_encoder = LabelEncoder()
data['relationship'] = relationship_encoder.fit_transform(data['relationship'])
joblib.dump(relationship_encoder, "relationship_encoder.pkl")

race_encoder = LabelEncoder()
data['race'] = race_encoder.fit_transform(data['race'])
joblib.dump(race_encoder, "race_encoder.pkl")

gender_encoder = LabelEncoder()
data['gender'] = gender_encoder.fit_transform(data['gender'])
joblib.dump(gender_encoder, "gender_encoder.pkl")

native_encoder = LabelEncoder()
data['native-country'] = native_encoder.fit_transform(data['native-country'])
joblib.dump(native_encoder, "native-country_encoder.pkl")

marital_encoder = LabelEncoder()
data['marital-status'] = marital_encoder.fit_transform(data['marital-status'])
joblib.dump(marital_encoder, "marital-status_encoder.pkl")

data

# dividing data into input and output
x=data.drop(columns=['income']) # input
y=data['income'] # output
x

# dividing data into input and output
x=data.drop(columns=['income']) # input
y=data['income'] # output
x

# Output
y

# using min max scalar for normalization
from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler()
x=scaler.fit_transform(x)
x

# Machine Learning Algorithm
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import  StandardScaler , OneHotEncoder

xtrain , xtest, ytrain , ytest = train_test_split(x,y,test_size=0.2,random_state=23,stratify=y)

models={
    "LogisticRegression" : LogisticRegression(),
    "RandomForest" : RandomForestClassifier(),
    "KNN" : KNeighborsClassifier(),
    "SVM" : SVC(),
    "gradientBoosting" : GradientBoostingClassifier()
}

results = {}

for name,model in models.items():
  pipe=Pipeline([
      ('scaler',StandardScaler()),
      ('model',model)
  ])

  pipe.fit(xtrain,ytrain)
  ypred=pipe.predict(xtest)
  acc=accuracy_score(ytest,ypred)
  results[name]=acc
  print(f"{name} Accuracy: {acc :.4f}")
  print(classification_report(ytest,ypred))

import matplotlib.pyplot as plt
plt.bar(results.keys(),results.values(),color='skyblue')
plt.ylabel('Accuracy Score')
plt.title('Model Comparison')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

#Get the best model
best_model_name=max(results,key=results.get)
best_model=models[best_model_name]
print(f"\n✅ Best model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Save the best model
import joblib
joblib.dump(best_model, "best_model.pkl")
print("✅ Saved best model as best_model.pkl")


#%%writefile app.py
import streamlit as st
import pandas as pd
import joblib


# Load encoders
workclass_encoder = joblib.load("workclass_encoder.pkl")
occupation_encoder = joblib.load("occupation_encoder.pkl")
relationship_encoder = joblib.load("relationship_encoder.pkl")
race_encoder =  joblib.load("race_encoder.pkl")
gender_encoder = joblib.load("gender_encoder.pkl")
native_encoder = joblib.load("native-country_encoder.pkl")
marital_encoder = joblib.load("marital-status_encoder.pkl")


# --- Load Trained Model ---
model = joblib.load("best_model.pkl")

# --- Page Config ---
st.set_page_config(page_title="Employee Salary Predictor", page_icon="💼", layout="wide")

# --- Styling ---
st.markdown("""
    <style>
        .main { background-color: #f5f5f5; }
        .stButton>button {
            background-color: #4CAF50;
            color: white;
            border-radius: 8px;
            font-weight: bold;
        }
        .stMarkdown {
            font-size: 16px;
        }
        .footer {
            font-size: 12px;
            text-align: center;
            margin-top: 50px;
            color: gray;
        }
    </style>
""", unsafe_allow_html=True)

# --- Title ---
st.title("💼 Employee Salary Prediction App")
st.markdown("#### 🔍 Predict whether an employee earns **>50K or ≤50K** using ML!")

st.markdown("---")

# --- Sidebar Inputs ---
st.sidebar.header("📋 Input Employee Details")

# ✨ Replace these fields with your dataset's actual input columns
with st.sidebar.form("user_input_form"):
    age = st.slider("👤 Age", 18, 65, 30)
    workclass = st.selectbox("🏢 Workclass", workclass_encoder.classes_)
    education = st.selectbox("🎓 Education Level", [
        "Bachelors", "Masters", "Doctorate", "Prof-school", "Assoc-acdm",
        "Assoc-voc", "Some-college", "HS-grad", "12th", "11th", "10th",
        "9th", "7th-8th", "5th-6th", "1st-4th"
    ])
    educational_num = st.slider("📚 Educational Number", 0, 16, 9) # Converted to slider
    marital_status = st.selectbox("❤️ Marital Status", marital_encoder.classes_)
    occupation = st.selectbox("💼 Job Role", occupation_encoder.classes_)
    relationship = st.selectbox("👨‍👩‍👧‍👦 Relationship", relationship_encoder.classes_)
    race = st.selectbox("🌍 Race", race_encoder.classes_)
    gender = st.selectbox("🚻 Gender", gender_encoder.classes_)
    capital_gain = st.slider("📈 Capital Gain", 0, 20000, 0, step=100)
    capital_loss = st.slider("📉 Capital Loss", 0, 2500, 0, step=100)
    hours_per_week = st.slider("⏱ Hours per Week", 20, 60, 40)
    native_country = st.selectbox("🇺🇸 Native Country", native_encoder.classes_)
    fnlwgt = st.slider("📊 Fnlwgt", 0, 1500000, 0, step=1000)


    submitted = st.form_submit_button("🔮 Predict")


# --- Single Prediction ---
if submitted:
    input_df = pd.DataFrame({
        'age': [age],
        'workclass': [workclass],
        'fnlwgt': [fnlwgt],
        'educational-num': [educational_num],
        'marital-status': [marital_status],
        'occupation': [occupation],
        'relationship' : [relationship],
        'race':[race],
        'gender' :[gender],
        'capital-gain': [capital_gain],
        'capital-loss': [capital_loss],
        'hours-per-week' : [hours_per_week],
        'native-country' : [native_country],
    })

    # Apply to input_df
    input_df_encoded = input_df.copy()
    input_df_encoded['workclass'] = workclass_encoder.transform(input_df_encoded['workclass'])
    input_df_encoded['occupation'] = occupation_encoder.transform(input_df_encoded['occupation'])
    input_df_encoded['relationship'] = relationship_encoder.transform(input_df_encoded['relationship'])
    input_df_encoded['race'] = race_encoder.transform(input_df_encoded['race'])
    input_df_encoded['gender'] = gender_encoder.transform(input_df_encoded['gender'])
    input_df_encoded['native-country'] = native_encoder.transform(input_df_encoded['native-country'])
    input_df_encoded['marital-status'] = marital_encoder.transform(input_df_encoded['marital-status'])

    # Drop the unused education column (educational-num is used)
    # input_df_encoded.drop(columns=['educational-num'], inplace=True) # Keep educational-num

    st.markdown("### 🧾 Input Summary")
    st.dataframe(input_df)

    # Prediction
    pred = model.predict(input_df_encoded)[0]
    label = ">50K" if pred == ">50K" else "<=50K" # Assuming model predicts string labels


    st.markdown("### 💡 Prediction Result")
    if label == ">50K":
        st.success("🎉 The predicted income is **greater than 50K**.")
    else:
        st.warning("💸 The predicted income is **less than or equal to 50K**.")


# --- Batch Prediction ---
st.markdown("---")
st.subheader("📂 Batch Prediction (Upload CSV)")

# Add a section to download a sample CSV
st.markdown("Download a sample CSV template for batch prediction:")
sample_data = pd.DataFrame(columns=['age', 'workclass', 'fnlwgt', 'educational-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'])
csv_template = sample_data.to_csv(index=False).encode('utf-8')
st.download_button(
    label="⬇️ Download Sample CSV",
    data=csv_template,
    file_name='salary_prediction_template.csv',
    mime='text/csv',
)


uploaded_file = st.file_uploader("Upload CSV with the same columns: age, workclass, fnlwgt, educational-num, marital-status, occupation, relationship, race, gender, capital-gain, capital-loss, hours-per-week, native-country", type="csv")

if uploaded_file:
    batch_data = pd.read_csv(uploaded_file)
    st.write("📄 Uploaded Data Preview:", batch_data.head())

    batch_data_encoded = batch_data.copy()
    # Apply encoders to batch data
    # Handle potential unseen labels during transformation by replacing them with a placeholder or the most frequent category
    for col, encoder in zip(['workclass', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'marital-status'],
                             [workclass_encoder, occupation_encoder, relationship_encoder, race_encoder, gender_encoder, native_encoder, marital_encoder]):
        # Use a try-except block to handle unseen labels during transform
        try:
            batch_data_encoded[col] = encoder.transform(batch_data_encoded[col])
        except ValueError as e:
            st.warning(f"Warning: Unseen labels found in column '{col}' during encoding: {e}. Replacing with a placeholder.")
            # Replace unseen labels with a placeholder or handle as appropriate
            # One approach is to replace unseen values with a value that will result in a specific encoded value (e.g., the encoded value of 'Others' or a new value for 'Unknown')
            # Here, I'll replace with the encoded value of 'Others' for workclass and occupation, and a placeholder for others.
            if 'Others' in encoder.classes_:
                 unseen_value_encoded = encoder.transform(['Others'])[0]
            else:
                # If 'Others' is not in classes, find a suitable default or handle differently
                unseen_value_encoded = -1 # Placeholder or a value that signifies 'Unknown'

            batch_data_encoded[col] = batch_data_encoded[col].apply(lambda x: encoder.transform([x])[0] if x in encoder.classes_ else unseen_value_encoded)


    # Drop education from batch data if it exists
    batch_data_encoded.drop(columns=['education'], errors='ignore', inplace=True)


    batch_preds = model.predict(batch_data_encoded)
    batch_data['Predicted Income'] = [">50K" if p == ">50K" else "<=50K" for p in batch_preds] # Assuming model predicts string labels

    # Decode categorical columns back to original values, handling potential errors
    for col, encoder in zip(['workclass', 'occupation', 'relationship', 'race', 'gender', 'native-country', 'marital-status'],
                             [workclass_encoder, occupation_encoder, relationship_encoder, race_encoder, gender_encoder, native_encoder, marital_encoder]):
        try:
            batch_data[col] = encoder.inverse_transform(batch_data_encoded[col])
        except ValueError as e:
             st.warning(f"Warning: Unseen labels found in column '{col}' during decoding: {e}. Cannot fully decode.")
             # If inverse_transform fails, the column will remain with encoded values or the placeholder if used during transform.
             # You might want to add a column indicating decoding issues or leave the encoded value.
             pass


    st.markdown("### ✅ Predictions:")
    st.write(batch_data.head())

    # Download button
    csv = batch_data.to_csv(index=False).encode('utf-8')
    st.download_button("⬇️ Download Result CSV", csv, "salary_predictions.csv", "text/csv")

# --- Footer ---
st.markdown("""
    <div style='text-align: center; font-size: 14px; color: gray;'>
        <br><br>
        Made with ❤️ using Streamlit | Powered by a Machine Learning Classifier Algorithm<br>
        Trained on the Adult Employee Dataset<br>
        © 2025 Chirag Jain(NIT KKR)
    </div>
    """, unsafe_allow_html=True)

from pyngrok import ngrok
import os
import threading

ngrok.set_auth_token("2zy0AYvF7x0z4guFHyGRkJW224z_4Py2JLrGqWC2AvnWfy1Pj")

# Start streamlit in a thread
def run_app():
    os.system("streamlit run app.py")

threading.Thread(target=run_app).start()

# Open ngrok tunnel
public_url = ngrok.connect(8501)
print("🌐 Streamlit app is live at:", public_url)